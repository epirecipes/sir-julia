{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Inference for a deterministic ODE model using RxInfer.jl\nSimon Frost (@sdwfrost), 2024-07-26\n\n## Introduction\n\n[`RxInfer.jl`](https://rxinfer.ml) is a reactive probabilistic programming library that allows for the definition of probabilistic models in a modular way. It uses (mostly) the same dynamic language, GraphPPL, as [Turing.jl](https://turing.ml), but the internal workings are very different. RxInfer.jl primarily uses message passing algorithms in order to achieve high performance. This notebook shows how to infer the parameters of a simple SIR model (as an ordinary differential equation) using `RxInfer.jl` and `OrdinaryDiffEq.jl`. For more technical information on how `RxInfer.jl` works, please see the [PhD thesis](https://pure.tue.nl/ws/portalfiles/portal/313860204/20231219_Bagaev_hf.pdf) of Dmitry Bagaev.\n\n## Libraries"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Pkg\nPkg.instantiate()"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using RxInfer\nusing OrdinaryDiffEq\nusing ExponentialFamilyProjection\nusing Optimisers\nusing StableRNGs\nusing StatsFuns\nusing StaticArrays\nusing Plots\nusing BenchmarkTools\nimport BayesBase;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transitions\n\nWe describe the transitions of the SIR model using the following ordinary differential equations; for efficiency, we use the `StaticArrays` package to define the state vector."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function sir_ode(u, p, t)\n    (S,I,R,C) = u\n    (β,c,γ) = p\n    N = S+I+R\n    infection = β*c*I/N*S\n    recovery = γ*I\n    return @SArray([\n         -infection,\n        infection - recovery,\n        recovery,\n        infection\n    ]) # S, I, R, C\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generative model\n\nThis function takes an existing `ODEProblem`, the length of the data, `l`, the proportion of the population that is initially infected, `i₀`, and the infectivity parameter, `β`, and outputs the daily incidence by taking the difference between cumulative cases."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function sir_ode_solve(problem, l, i₀, β)\n    I = i₀*1000.0\n    S = 1000.0 - I\n    u0 = @SArray([S, I, 0.0, 0.0])\n    p = @SArray([β, 10.0, 0.25])\n    prob = remake(problem; u0=u0, p=p)\n    sol = solve(prob, Tsit5(), saveat = 1.0)\n    sol_C = view(sol, 4, :) # Cumulative cases\n    sol_X = Array{eltype(sol_C)}(undef, l)\n    @inbounds @simd for i in 1:length(sol_X)\n        sol_X[i] = sol_C[i + 1] - sol_C[i]\n    end\n    return sol_X\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We assume that the daily incidence is Poisson-distributed with the mean given by the output of the ODE. The following function generates simulated data."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function simulate_data(l, i₀, β)\n    prob = ODEProblem(sir_ode, @SArray([990.0, 10.0, 0.0, 0.0]), (0.0, l), @SArray([β, 10.0, 0.25]))\n    X = sir_ode_solve(prob, l, i₀, β)\n    Y = rand.(Poisson.(X))\n    return X, Y\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference\n\nTo make inference using RxInfer.jl efficient, we will treat the output of the ODE as a single node in the factor graph.\n\n### Defining a node\n\nWe first define a new node type, `ODEFused`, that takes the initial proportion of the population that is infected, `i₀`, the infectivity parameter, `β`, the length of the data, `l`, and the `ODEProblem` as fields."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "struct ODEFused{I, B, L, F} <: DiscreteMultivariateDistribution\n    i₀::I\n    β::B\n    l::L\n    problem::F\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function defines the log-likelihood of the node, which is the sum of the log-likelihoods of the Poisson-distributed observations for each day."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function BayesBase.logpdf(ode::ODEFused, y::Vector)\n    sol_X = sir_ode_solve(ode.problem, ode.l, ode.i₀, ode.β)\n    # `sum` over individual entries of the result of the `ODE` solver\n    sumlpdf = sum(zip(sol_X, y)) do (x_i, y_i)\n        return logpdf(Poisson(abs(x_i)), y_i)\n    end\n    # `clamp` to avoid infinities in the beginning, where \n    # priors are completely off\n    return clamp(sumlpdf, -100000, Inf)\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function BayesBase.insupport(ode::ODEFused, y::Vector)\n    return true\nend\n\nfunction BayesBase.mean(p::PointMass{D}) where { D <: ODEProblem }\n    return p.point\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then define a new node, using the `@node` macro."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@node ODEFused Stochastic [ y, i₀, β, l, problem ];"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the problem\n\nNow that we have defined a node for the differential equation, we can define the model. We use a `Beta(1,1)` prior for the initial proportion of the population that is infected, `i₀`, and the infectivity parameter, `β`; these are vague priors in that the density is flat, and bounded between 0 and 1."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@model function bayes_sir(y)\n    l = length(y)\n    prob = ODEProblem(sir_ode, @SArray([990.0, 10.0, 0.0, 0.0]), (0.0, l), @SArray([0.05, 10.0, 0.25]))    \n    i₀ ~ Beta(1.0, 1.0)\n    β  ~ Beta(1.0, 1.0)\n    y  ~ ODEFused(i₀, β, l, prob)\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constraints\n\nAlthough a beta prior for the parameters `i₀` and `β` may seem reasonable, it complicates inference, as a Beta prior is not conjugate to the Poisson likelihood. We can use the `ExponentialFamilyProjection` package to project the posterior of the parameters to a more tractable distribution (see [here](https://reactivebayes.github.io/RxInfer.jl/stable/manuals/inference/nonconjugate/) for more details). The projection constraint must be specified using the @constraints macro; In this case, we use the `ControlVariateStrategy`. The number of samples used is a balance between accuracy and time; when the number of samples is too low, inference can fail, while if the number of samples is high, then inference takes a long time. After a little experimentation, 200 samples was found to give stable inference with a reasonable running time. The `MeanField` constraint assumes that the variables `i₀` and `β` are independent."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@constraints function sir_constraints()\n    parameters = ProjectionParameters(\n        strategy = ExponentialFamilyProjection.ControlVariateStrategy(nsamples = 200)\n    )\n\n    # In principle different parameters can be used for different states\n    q(i₀) :: ProjectedTo(Beta; parameters = parameters)\n    q(β) :: ProjectedTo(Beta; parameters = parameters)\n\n    # `MeanField` is required for `NodeFunctionRuleFallback`\n    q(i₀, β) = MeanField()\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialization\n\nWe initialize the distributions of the parameters `i₀` and `β` using a `Beta(1,1)` distribution for each."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@initialization function sir_initialization()\n    q(β)  = Beta(1, 1)\n    q(i₀) = Beta(1, 1)\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting the model\n\n### Simulating data"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "β_true = 0.05\ni₀_true = 0.01\nl = 40\nX, Y = simulate_data(l, i₀_true, β_true);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "ts = 1.0:1.0:l\nplot(ts, X, label=\"Deterministic mean\", xlabel=\"Time\", ylabel=\"Daily incidence\")\nscatter!(ts, Y, label=\"Simulated observations\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "niter = 15\nresult = infer(\n        model = bayes_sir(),\n        data  = (y = Y, ),\n        constraints = sir_constraints(),\n        initialization = sir_initialization(),\n        iterations = niter,\n        showprogress = false,\n        options = (\n            # Read `https://reactivebayes.github.io/RxInfer.jl/stable/manuals/inference/undefinedrules/`\n            rulefallback = NodeFunctionRuleFallback(),\n        )\n);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing the results\n\nWe can check whether enough iterations were used by plotting the mean of the posterior distributions of `i₀` and `β` by iteration."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "pl_β_mean_i = plot(1:15, [mean(x) for x in result.posteriors[:β]], label=false, xlabel=\"Iteration\", ylabel=\"Mean\", title=\"β\")\npl_i₀_mean_i = plot(1:15, [mean(x) for x in result.posteriors[:i₀]], label=false, xlabel=\"Iteration\", ylabel=\"Mean\", title=\"i₀\")\nplot(pl_β_mean_i, pl_i₀_mean_i, layout=(1,2), plot_title=\"Mean of posterior by iteration\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We take the estimates of `i₀` and `β` from the last iteration."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "posterior_i₀ = result.posteriors[:i₀][end]\nposterior_β = result.posteriors[:β][end];"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "mean_var(posterior_i₀) # Should be 0.01"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "mean_var(posterior_β) # Should be 0.05"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the results\n\nThe following code plots the posterior distributions of the parameters `i₀` and `β`; in both cases, the model appears to give reasonable estimates."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "p1 = plot(0.0:0.0001:0.02, x -> pdf(posterior_i₀, x); label=\"q(i₀)\")\nvline!(p1, [i₀_true], label=false)\np2 = plot(0.04:0.0001:0.06, x -> pdf(posterior_β, x); label=\"q(β)\")\nvline!(p2, [β_true], label=false)\nplot(p1, p2)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benchmarking\n\nThe following code demonstrates that inference using RxInfer is very fast for this example, in addition to giving good parameter estimates."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@benchmark infer(\n        model = bayes_sir(),\n        data  = (y = Y, ),\n        constraints = sir_constraints(),\n        initialization = sir_initialization(),\n        iterations = niter,\n        showprogress = false,\n        options = (\n            # Read `https://reactivebayes.github.io/RxInfer.jl/stable/manuals/inference/undefinedrules/`\n            rulefallback = NodeFunctionRuleFallback(),\n        )\n)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coverage\n\nWe can get a better idea of the accuracy of the inference by generating multiple simulated datasets and fitting the model. The rapid inference allows us to repeat the process for many simulated datasets. To speed up these calculations, we will split the computation up over multiple threads. We first need to load the `Base.Threads` module."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Base.Threads"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can check the number of threads available."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "Threads.nthreads()"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now use the `Threads.@threads` macro to parallelize the simulation and inference process."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "nsims = 1000\ni₀_mean = Array{Float64}(undef, nsims)\nβ_mean = Array{Float64}(undef, nsims)\ni₀_coverage = Array{Float64}(undef, nsims)\nβ_coverage = Array{Float64}(undef, nsims)\nThreads.@threads for i in 1:nsims\n    X_sim, Y_sim = simulate_data(l, i₀_true, β_true)\n    r = infer(\n              model = bayes_sir(),\n              data  = (y = Y_sim, ),\n              constraints = sir_constraints(),\n              initialization = sir_initialization(),\n              iterations = niter,\n              showprogress = false,\n              options = ( rulefallback = NodeFunctionRuleFallback(), ))\n    i0 = r.posteriors[:i₀][end]\n    i₀_mean[i] = mean(i0)\n    i0_cov = cdf(i0, i₀_true)\n    b = r.posteriors[:β][end]\n    β_mean[i] = mean(b)\n    b_cov = cdf(b, β_true)\n    i₀_coverage[i] = i0_cov\n    β_coverage[i] = b_cov\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the credible intervals are well calibrated, we expect that the distribution of the CDF of the true value (across multiple simulated datasets) should be uniform."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# Convenience function to check if the true value is within the credible interval\nfunction in_credible_interval(x, lwr=0.025, upr=0.975)\n    return x >= lwr && x <= upr\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "pl_β_coverage = histogram(β_coverage, bins=0:0.1:1.0, label=false, title=\"β\", ylabel=\"Density\", density=true, xrotation=45, xlim=(0.0,1.0))\npl_i₀_coverage = histogram(i₀_coverage, bins=0:0.1:1.0, label=false, title=\"i₀\", ylabel=\"Density\", density=true, xrotation=45, xlim=(0.0,1.0))\nplot(pl_β_coverage, pl_i₀_coverage, layout=(1,2), plot_title=\"Distribution of CDF of true value\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The coverage of the 95% credible intervals is given by the proportion of simulations where the true value is within the interval."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sum(in_credible_interval.(β_coverage)) / nsims"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sum(in_credible_interval.(i₀_coverage)) / nsims"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also look at the distribution of the posterior means, which should fall around the true value."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "pl_β_mean = histogram(β_mean, label=false, title=\"β\", ylabel=\"Density\", density=true, xrotation=45, xlim=(0.045, 0.055))\nvline!([β_true], label=\"True value\")\npl_i₀_mean = histogram(i₀_mean, label=false, title=\"i₀\", ylabel=\"Density\", density=true, xrotation=45, xlim=(0.0,0.02))\nvline!([i₀_true], label=\"True value\")\nplot(pl_β_mean, pl_i₀_mean, layout=(1,2), plot_title=\"Distribution of posterior means\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above, we can see that there is a (small) bias in the parameter estimates, contributing to the non-uniform nature of the coverage plots above. It may be worth looking into methods (e.g. Bayesian conformal prediction) to try to quantify uncertainty more accurately."
      ],
      "metadata": {}
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.10.3"
    },
    "kernelspec": {
      "name": "julia-1.10",
      "display_name": "Julia 1.10.3",
      "language": "julia"
    }
  },
  "nbformat": 4
}
