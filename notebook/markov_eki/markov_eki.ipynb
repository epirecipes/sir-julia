{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting a stochastic, discrete-time Markov model using Ensemble Kalman Inversion in EnsembleKalmanProcesses.jl\nSimon Frost (@sdwfrost), 2023-03-16\n\n## Introduction\n\nFitting stochastic models to data is more challenging than fitting deterministic models. This example uses [`EnsembleKalmanProcesses.jl`](https://github.com/CliMA/EnsembleKalmanProcesses.jl) to fit a stochastic, discrete-time Markov model to simulated data using [Ensemble Kalman Inversion](https://arxiv.org/abs/1808.03620), which returns point estimates of parameter values.\n\n## Libraries"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using OrdinaryDiffEq\nusing EnsembleKalmanProcesses\nusing EnsembleKalmanProcesses.ParameterDistributions\nconst EKP = EnsembleKalmanProcesses\nusing Random\nusing LinearAlgebra # Provides identity matrix `I`\nusing Distributions\nusing ThreadsX\nusing Plots\nusing StatsPlots;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transitions\n\nWe use a stochastic, discrete-time Markov model to describe the dynamics. The following model assumes that the time step, `dt` is 1, and takes 10 smaller steps (with `δt=0.1`) within the function. This allows us to reset the number of cases, `C` to zero each time step, without having to use callbacks or the SciML integrator interface. We scale the infectivity parameter β by dividing by the population size, so that is is on approximately the same scale as γ and I₀."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function sir_markov(u,p,t)\n    (S, I, C) = u\n    C = 0\n    (β, γ, N) = p\n    δt = 0.1\n    nsteps = 10\n    for i in 1:nsteps\n        ifrac = 1-exp(-β*I/N*δt)\n        rfrac = 1-exp(-γ*δt)\n        infection = rand(Binomial(S,ifrac))\n        recovery = rand(Binomial(I,rfrac))\n        S = S-infection\n        I = I+infection-recovery\n        C = C+infection\n    end\n   [S, I, C]\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time, initial conditions, and parameter values"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "tspan = (0,40)\nu0 = [990, 10, 0] # S, I, C\nβ = 0.5\nγ = 0.25\nN = 1000\ni₀ = 0.01\np = [β, γ, N]\nseed = 1234;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the model\n\nWe perform a single run of the model to illustrate the dynamics."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "Random.seed!(seed)\nprob = DiscreteProblem(sir_markov, u0, tspan, p)\nsol = solve(prob, FunctionMap())\nplot(sol, labels=[\"S\" \"I\" \"C\"], xlabel=\"Time\", ylabel=\"Number\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will base inference on either (a) summary statistics (the peak number of cases, the time of the peak, and the total number of cases over the period `tspan`) or (b) on the number of new cases per day, `C`. For the latter, we calculate log(C+1) in order to generate data that more closely approximates a multivariate Gaussian distribution."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "C = Float64.(hcat(sol.u...)[3,2:end])\nsummary_stats = [maximum(C), Float64(argmax(C)),  sum(C)]\ncases = log.(C .+ 1);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating simulated data\n\nWe will infer the infectivity parameter, β, and the fraction of initial infected individuals, i₀ from either the summary statistics or the time series of new cases per day. EnsembleKalmanProcesses.jl expects a function that takes a vector of parameter values (here called `q` so as not to clash with the parameter vector for the model, `p`), and returns a vector of simulated data."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function get_summary_stats(q)\n    i0 = Float64(round(N*q[2]))\n    problem = remake(prob, p=[q[1], γ, N],u0=[N-i0,i0,0.0])\n    sol = solve(problem, FunctionMap())\n    C = Float64.(hcat(sol.u...)[3,2:end])\n    return [maximum(C), Float64(argmax(C)),  sum(C)]\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function get_cases(q)\n    i0 = Float64(round(N*q[2]))\n    problem = remake(prob, p=[q[1], γ, N],u0=[N-i0,i0,0.0])\n    sol = solve(problem, FunctionMap())\n    C = Float64.(hcat(sol.u...)[3,2:end])\n    return log.(C .+ 1)\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We generate a batch of summary statistics and cases in order to examine the distribution of the data."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sumstats = [get_summary_stats([β, i₀]) for i in 1:1000]\nsumstats = hcat(sumstats...);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "corrplot(sumstats', title=\"Summary statistics\", labels=[\"Peak\" \"Peak time\" \"Total\"])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "simcases = [get_cases([β, i₀]) for i in 1:1000]\nsimcases = hcat(simcases...);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of datapoints (40) is too high to show on a `corrplot`, so we sample at `t=10,20,30` to inspect the joint distribution."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "corrplot(simcases'[:,10:10:30], title=\"Cases\", labels=[\"t=10\" \"t=20\" \"t=30\"])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Priors\n\nA `constrained_gaussian(\"name\", 0.5, 0.3, 0.0, 1.0)` will give a prior close to a uniform variable between 0 and 1; below, we transform this to give approximate uniform distributions for β (between 0 and 1) and i₀ (between 0 and 0.1)."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "prior_u1 = constrained_gaussian(\"β\", 0.5, 0.3, 0.0, 1.0)\nprior_u2 = constrained_gaussian(\"i₀\", 0.05, 0.03, 0.0, 0.1)\nprior = combine_distributions([prior_u1, prior_u2]);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(prior)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble Kalman Inversion\n\nThe `Inversion()` process takes a user-defined prior, a summary of the observation statistics given by the mean `y` and covariance `Γ`, and a desired number of members in the ensemble.\n\n### Initialization\n\nFor numerical stability, we define a small regularization factor, `Γ` (here `LinearAlgebra.I` refers to the identity matrix)."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "Γ = 1e-4 * LinearAlgebra.I;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference based on summary statistics"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "N_iterations_ss = 50\nN_ensemble_ss = 1000\nrng_ss = Random.Xoshiro(seed)\ninitial_ensemble_ss = EKP.construct_initial_ensemble(rng_ss, prior, N_ensemble_ss);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following, we set `deterministic_forward_map = false`, as we have a stochastic model. We use multiple threads to speed up the simulations across the ensemble."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "eki_obj_ss = EKP.EnsembleKalmanProcess(initial_ensemble_ss, summary_stats, Γ, Inversion(); rng = rng_ss)\nfor i in 1:N_iterations_ss\n    params_i = get_ϕ_final(prior, eki_obj_ss)\n    # Without threads would be as follows\n    # ss = hcat([get_summary_stats(params_i[:, i]) for i in 1:N_ensemble_ss]...)\n    ss = hcat(ThreadsX.collect(get_summary_stats(params_i[:, i]) for i in 1:N_ensemble_ss)...)\n    EKP.update_ensemble!(eki_obj_ss, ss, deterministic_forward_map = false)\nend\nprior_ensemble_ss = get_ϕ(prior, eki_obj_ss, 1)\nfinal_ensemble_ss = get_ϕ_final(prior, eki_obj_ss)\nϕ_optim_ss = get_ϕ_mean_final(prior, eki_obj_ss)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This calculates the mean and the standard deviation of the ensemble across iterations."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "ϕ_mean_ss = hcat([mean(get_ϕ(prior, eki_obj_ss, i),dims=2) for i in 1:N_iterations_ss]...)\nϕ_std_ss = hcat([std(get_ϕ(prior, eki_obj_ss, i),dims=2) for i in 1:N_iterations_ss]...);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot shows how the parameter estimates change over iterations, as captured by the mean and standard deviation of the ensemble."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "p1 = plot(1:N_iterations_ss, ϕ_mean_ss[1,:],label=\"β\",xlabel=\"Iteration\",yaxis=:log,title=\"Mean\")\nplot!(p1, 1:N_iterations_ss, ϕ_mean_ss[2,:],label=\"i₀\")\np2 = plot(1:N_iterations_ss, ϕ_std_ss[1,:],label=\"β\",xlabel=\"Iteration\",yaxis=:log,title=\"St. dev.\")\nplot!(p2, 1:N_iterations_ss, ϕ_std_ss[2,:],label=\"i₀\")\nplot(p1, p2, layout = @layout [a b])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot shows the prior distribution and the distribution of the ensemble after `N_iterations_ss` iterations. It is important to note that the variability in the ensemble after filtering does not capture uncertainty in the parameter estimate."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "l = @layout [a b; c d]\np1 = histogram(prior_ensemble_ss[1,:], legend=false, title=\"β\", xlim=(0, 1.0), bins=0:0.01:1.0)\np2 = histogram(prior_ensemble_ss[2,:], legend=false, title=\"i₀\", xlim=(0, 0.1), bins=0:0.001:0.1)\n\np3 = histogram(final_ensemble_ss[1,:], legend=false, title=\"β\", xlim=(0, 1.0), bins=0:0.01:1.0)\np4 = histogram(final_ensemble_ss[2,:], legend=false, title=\"i₀\", xlim=(0, 0.1), bins=0:0.001:0.1)\nplot(p1, p3, p2, p4, layout=l)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference based on case time series\n\nWe repeat the above, but now for case data, which is of higher dimension (40) compared to the summary statistics (3). Correspondingly, we set the number of ensemble members higher."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "N_iterations_cs = 50\nN_ensemble_cs = 10000\nrng_cs = Random.Xoshiro(seed)\ninitial_ensemble_cs = EKP.construct_initial_ensemble(rng_cs, prior, N_ensemble_cs);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "eki_obj_cases = EKP.EnsembleKalmanProcess(initial_ensemble_cs, cases, Γ, Inversion(); rng = rng_cs)\nfor i in 1:N_iterations_cs\n    params_i = get_ϕ_final(prior, eki_obj_cases)\n    # cs = hcat([get_cases(params_i[:, i]) for i in 1:N_ensemble_cs]...)\n    cs = hcat(ThreadsX.collect(get_cases(params_i[:, i]) for i in 1:N_ensemble_cs)...)\n    EKP.update_ensemble!(eki_obj_cases, cs, deterministic_forward_map = false)\nend\nprior_ensemble_cases = get_ϕ(prior, eki_obj_cases, 1)\nfinal_ensemble_cases = get_ϕ_final(prior, eki_obj_cases)\nϕ_optim_cases = get_ϕ_mean_final(prior, eki_obj_cases)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "ϕ_mean_cases = hcat([mean(get_ϕ(prior, eki_obj_cases, i),dims=2) for i in 1:N_iterations_cs]...)\nϕ_std_cases = hcat([std(get_ϕ(prior, eki_obj_cases, i),dims=2) for i in 1:N_iterations_cs]...);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "p1 = plot(1:N_iterations_cs, ϕ_mean_cases[1,:],label=\"β\",xlabel=\"Iteration\",yaxis=:log,title=\"Mean\")\nplot!(p1, 1:N_iterations_cs, ϕ_mean_cases[2,:],label=\"i₀\")\n\np2 = plot(1:N_iterations_cs, ϕ_std_cases[1,:],label=\"β\",xlabel=\"Iteration\",yaxis=:log,title=\"St. dev.\")\nplot!(p2, 1:N_iterations_cs, ϕ_std_cases[2,:],label=\"i₀\")\nplot(p1, p2, layout = @layout [a b])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we plot the prior and final distribution of the ensemble."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "l = @layout [a b; c d; e f]\np1 = histogram(prior_ensemble_cases[1,:], legend=false, title=\"β\", xlim=(0, 1.0), bins=0:0.01:1.0)\np2 = histogram(prior_ensemble_cases[2,:], legend=false, title=\"i₀\", xlim=(0, 0.1), bins=0:0.001:0.1)\n\np3 = histogram(final_ensemble_cases[1,:], legend=false, title=\"β\", xlim=(0, 1.0), bins=0:0.01:1.0)\np4 = histogram(final_ensemble_cases[2,:], legend=false, title=\"i₀\", xlim=(0, 0.1), bins=0:0.001:0.1)\nplot(p1, p3, p2, p4, layout=l)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion\n\nEnsemble Kalman Inversion returns point estimates; if we are interested in obtaining measures of uncertainty, we can use approaches such as the [Ensemble Kalman Sampler](https://clima.github.io/EnsembleKalmanProcesses.jl/dev/ensemble_kalman_sampler/) or [Unscented Kalman Inversion](https://clima.github.io/EnsembleKalmanProcesses.jl/dev/unscented_kalman_inversion/). However, EKI with summary statistics provides a means to rapidly get reasonable starting parameter estimates for other approaches."
      ],
      "metadata": {}
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.8.5"
    },
    "kernelspec": {
      "name": "julia-1.8",
      "display_name": "Julia 1.8.5",
      "language": "julia"
    }
  },
  "nbformat": 4
}
