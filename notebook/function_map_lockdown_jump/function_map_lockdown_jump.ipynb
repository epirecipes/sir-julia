{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Optimal control of an SIR epidemic with a non-pharmaceutical intervention using JuMP.jl\nSimon Frost (@sdwfrost), 2023-04-27\n\n## Introduction\n\nThis example considers the optimal control of an SIR epidemic through an intervention which reduces infection, according to the following set of equations. `S` is the number of susceptible individuals, `I` is the number of infected individuals, and `C` is the total number of cases. The infection rate is reduced according to a policy `υ(t)`. The optimal control problem is specified as the policy that minimizes the total number of cases (i.e. the final size) under the constraints (a) that `υ` cannot exceed a maximum value and (b) there is a cost, measured as the integral of `υ` over time, which cannot exceed a certain level.\n\n$$\n\\begin{align*}\n\\dfrac{\\mathrm dS}{\\mathrm dt} &= -\\beta (1 - \\upsilon(t)) S I, \\\\\n\\dfrac{\\mathrm dI}{\\mathrm dt} &= \\beta (1 - \\upsilon(t)) S I - \\gamma I,\\\\ \n\\dfrac{\\mathrm dC}{\\mathrm dt} &= \\beta (1 - \\upsilon(t)) S I\\\\\n\\end{align*}\n$$\n\nThe policy, `υ(t)`, is an infinite parameter, as it is defined over a continuous domain (time). [Britton and Leskela (2022)](https://arxiv.org/abs/2202.07780) have shown that the optimal policy for the above model is one with a single lockdown at the maximum level for `υ`, which is sustained until the cost has been reached. To determine whether the optimal policy can be identified numerically, we discretize the system using a fixed time step (as in [this example](https://github.com/epirecipes/sir-julia/blob/master/markdown/function_map/function_map.md)), and then use `JuMP.jl` to optimize.\n\n## Libraries"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using JuMP\nusing Ipopt\nusing Plots;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters\n\nWe set the parameters, which includes the maximum intervention level, `υ_max`, and the cost, which is the integral of the intervention level over time, `υ_total`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "β = 0.5 # infectivity rate\nγ = 0.25 # recovery rate\nυ_max = 0.5 # maximum intervention\nυ_total = 10.0; # maximum cost\nsilent = true"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time domain\n\nWe set the time horizon to be long enough for the system to settle down to an equilibrium. We use a grid of timepoints fine enough to capture a wide variety of policy shapes, but coarse enough to keep the number of policy parameters to optimize low."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "t0 = 0.0\ntf = 100.0\ndt = 1.0;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial conditions\n\nWe set the initial conditions for the number of susceptibles, infecteds, and the total number of cases."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "S₀ = 0.99\nI₀ = 0.01\nC₀ = 0.00;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model setup\n\nWe specify a model using `JuMP.Model`, passing an optimizer."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "model = Model(Ipopt.Optimizer)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now declare the number of timesteps, `T`, and vectors of our model variables, each `T+1` steps long."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "T = Int(tf/dt)\n@variable(model, S[1:(T+1)])\n@variable(model, I[1:(T+1)])\n@variable(model, C[1:(T+1)])\n@variable(model, υ[1:(T+1)]);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We constrain the variables, `S`, `I`, and `C` to be at their initial conditions for the first element of the array, and between 0 and 1 (as we are using proportions) for the others."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# Initial conditions\n@constraint(model, S[1]==S₀)\n@constraint(model, I[1]==I₀)\n@constraint(model, C[1]==C₀)\n\n# Constraints on variables\n@constraint(model, [t=2:(T+1)], 0 ≤  S[t] ≤ 1)\n@constraint(model, [t=2:(T+1)], 0 ≤  I[t] ≤ 1)\n@constraint(model, [t=2:(T+1)], 0 ≤  C[t] ≤ 1);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We constrain our policy, `υ(t)` to lie between 0 and `υ_max`, and constrain the integral of the intervention to be less than or equal to `υ_total`, assuming that the intervention is piecewise constant during each time step."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@constraint(model, [t=1:(T+1)], 0 ≤  υ[t] ≤ υ_max)\n@constraint(model, dt*sum(υ) ≤ υ_total);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "To simplify the model constraints, we define nonlinear expressions for infection and recovery. We only need a vector that is `T` steps long."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@NLexpression(model, infection[t=1:T], (1-exp(-(1 - υ[t]) * β * I[t] * dt)) * S[t])\n@NLexpression(model, recovery[t=1:T], (1-exp(-γ*dt)) * I[t]);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now add additional constraints corresponding to the function map for `S`, `I`, and `C`. These have to be nonlinear constraints due to the inclusion of nonlinear expressions."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@NLconstraint(model, [t=1:T], S[t+1] == S[t] - infection[t])\n@NLconstraint(model, [t=1:T], I[t+1] == I[t] + infection[t] - recovery[t])\n@NLconstraint(model, [t=1:T], C[t+1] == C[t] + infection[t]);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We declare our objective as minimizing the total number of cases at the final timepoint."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@objective(model, Min, C[T+1]);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the model\n\nWe optimize the model in-place."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "if silent\n    set_silent(model)\nend\noptimize!(model)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can check the termination status of the optimizer, to check whether it has converged."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "termination_status(model)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post-processing\n\nWe can now extract the optimized values of `S`, `I`, and `C`, as well as the optimal policy, `υ`, as follows."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "S_opt = value.(S)\nI_opt = value.(I)\nC_opt = value.(C)\nυ_opt = value.(υ)\nts = collect(0:dt:tf);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting\n\nThe optimal value for `t₁` is obtained from [this example](https://github.com/epirecipes/sir-julia/blob/master/markdown/ode_lockdown_optimization/ode_lockdown_optimization.md)."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "t₁ = 14.338623046875002\nt₂ = t₁ + υ_total/υ_max"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the results demonstrates that the optimizer has identified a policy close to the optimal one, which is a single lockdown of intensity `υ_max` and a duration `υ_total/υ_max`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(ts, S_opt, label=\"S\", xlabel=\"Time\", ylabel=\"Number\")\nplot!(ts, I_opt, label=\"I\")\nplot!(ts, C_opt, label=\"C\")\nplot!(ts, υ_opt, label=\"Optimized υ\")\nvspan!([t₁, t₂], color=:gray, alpha=0.5, label=\"Exact υ\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion\n\nVarious time steps and number of steps were used in putting this example together. The coarse discretization used above results in very rapid convergence and results close to the optimum based on the continuous time system. Smaller timesteps, although giving results closer to the continuous time system, resulted in the solver struggling to converge due to the larger number of parameters. Reducing the time window, `tf`, in order to reduce the number of parameters was partially successful, but then the system may not have settled down to an equilibrium, and so the computed final size is an underestimate, shifting the intervention earlier. The estimates of the optimal policy obtained using the coarse discretization above could be used as start values for a system with a smaller timestep, which may prevent the system settling on an infeasible point."
      ],
      "metadata": {}
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.9.0"
    },
    "kernelspec": {
      "name": "julia-1.9",
      "display_name": "Julia 1.9.0",
      "language": "julia"
    }
  },
  "nbformat": 4
}
