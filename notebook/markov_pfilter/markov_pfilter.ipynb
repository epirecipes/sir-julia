{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting a stochastic, discrete-time Markov model using a simple particle filter\nSimon Frost (@sdwfrost), 2023-03-16\n\n## Introduction\n\nThis example presents perhaps the simplest particle filter (also known as sequential Monte Carlo) approach for fitting a stochastic model to data. The algorithm proceeds by fixing a set of parameter values, simulating a model one step at a time, and at each time step, resampling states that are consistent with the observed data. In this example, we require that the simulations are an exact match for the data i.e. we assume that there is no measurement error, and all the variability comes from the stochasticity of the model dynamics. Under this assumption, the proportion of simulations that are accepted each time step is an estimate of the partial likelihood. By summing the log-likelihoods across timepoints, we can use the particle filter to obtain an estimate of the likelihood of the data given the model. Rather than optimize this (noisy) likelihood, we use a simple line search separately for two parameters - the infectivity parameter, β, and the initial number of infected individuals, I₀.\n\n## Libraries"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using OrdinaryDiffEq\nusing Random\nusing Distributions\nusing StatsBase\nusing ThreadsX\nusing Plots\nusing Loess"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transitions\n\nThe model is a stochastic, discrete-time model in which each step (`dt=1`) in the simulation is made up of 10 smaller steps; this allows us to reset the number of new cases per timestep, `C`, to zero every timestep without recourse to callbacks, etc.."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function sir_markov(u,p,t)\n    (S, I, _) = u\n    C = 0\n    (β, γ, N) = p\n    δt = 0.1\n    nsteps=10\n    for i in 1:nsteps\n        ifrac = 1-exp(-β*I/N*δt)\n        rfrac = 1-exp(-γ*δt)\n        infection = rand(Binomial(S,ifrac))\n        recovery = rand(Binomial(I,rfrac))\n        S = S-infection\n        I = I+infection-recovery\n        C = C+infection\n    end\n   [S, I, C]\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time, initial conditions, and parameter values\n\nWe set the number of particles in our particle filter to a high value in order to avoid filtering failures (when none of the particles produces a valid state) and to reduce the noise in the likelihood estimate."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "tspan = (0,40)\nu0 = [990, 10, 0] # S, I, C\nβ = 0.5\nγ = 0.25\nN = 1000\np = [β, γ, N] # β, γ, N\nseed = 1234\nnparticles = 100000;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random number seed"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "Random.seed!(seed);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the model\n\nWe run the model once in order to obtain simulated data for the number of new cases per timestep, `C`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "prob = DiscreteProblem(sir_markov, u0, tspan, p, dt=1)\nsol = solve(prob, FunctionMap())\nC = hcat(sol.u...)[3,2:end];"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A simple particle filter\n\nThis particle filter makes use of the [SciML integrator interface](https://docs.sciml.ai/DiffEqDocs/stable/basics/integrator/) to (a) create a set of integrators (which correspond to our particles), (b) to perform a single timestep for each particle, and (c) to reinitialize particles with resampled states. Particle filters can fail i.e. none of the particles give a valid state; the following code handles this in a naive way, by returning a log likelihood of `-Inf`. The impact of this can be reduced by using a large number of particles."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function pfilter(prob, p, u0, C, nparticles=nparticles, seed=seed)\n    # Remake with parameters and initial conditions\n    prob = remake(prob, p=p, u0=u0)\n    # Generate a vector of integrators\n    integrators = [init(prob, FunctionMap(),save_everystep=true) for i in 1:nparticles]\n    # Initialize\n    Random.seed!(seed)\n    liks = zeros(Float64,length(C))\n    weights = Weights(zeros(Float64,nparticles))\n    us = [copy(u0) for i in 1:nparticles]\n    idx = collect(1:nparticles)\n    # Filter each timepoint\n    @inbounds for t in 1:length(C)\n        step!.(integrators) # Take a step\n        c = C[t] # The data at t\n        [us[i] = integrators[i].u for i in 1:nparticles]\n        [weights[i]=Float64(us[i][3]==c) for i in 1:nparticles] # 1.0 if state==c, 0.0 otherwise\n        liks[t] = mean(weights)\n        # Some naive failure handling\n        if mean(weights)==0.0\n            return -Inf\n            break\n        end\n        # Resample indices according to weights\n        sample!(1:nparticles, weights, idx)\n        # Reinitialize integrators with resampled states\n        [reinit!(integrators[i],us[idx[i]]) for i in 1:nparticles]\n    end\n    sum(log.(liks))\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the estimate of the likelihood at the true parameter values."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "pfilter(prob, p, u0, C, nparticles, seed)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1D parameter sweep for β\n\nTo examine how the likelihood changes over the parameter space, we perform a parameter sweep over a range of values for β, using threads to parallelize the simulations."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "## Array of β values\nbetas = collect(0.35:0.005:0.7)\n# Use ThreadsX to parallelise across parameter runs\n@time beta_liks = ThreadsX.collect(pfilter(prob, [beta, γ, N], u0, C, nparticles, seed) for beta in betas);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The values for the likelihood obtained from the particle filter are noisy estimates, so we generate a smooth curve to identify the maximum likelihood, excluding any failed runs."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "betas_failed = beta_liks.==-Inf\nbetas_success = betas[.!betas_failed]\nbeta_liks_success = beta_liks[.!betas_failed]\nbetas_model = loess(betas_success, beta_liks_success)\nbeta_liks_smooth = Loess.predict(betas_model, betas_success)\nβ̂=betas_success[argmax(beta_liks_smooth)]"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(betas_success,\n    beta_liks_smooth,\n    xlabel=\"β\",\n    ylabel=\"Log likelihood\",\n    label=\"\",\n    legend=true,\n    marker=false)\nscatter!(betas, beta_liks, label=\"\")\nvline!([p[1]],label=\"True β\")\nvline!([β̂],label=\"Estimated β\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1D parameter sweep for I₀\n\nThe number of initial infected is a discrete parameter, so we create a grid of `I₀=1:20`. As it turns out, the likelihood surface is quite flat, so we need a larger number of particles to reduce the noise in the likelihood estimates."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "I0s = collect(1:20)\n@time I0s_liks = ThreadsX.collect(pfilter(prob, [β, γ, N], [N-I0, I0, 0], C, 2*nparticles, seed) for I0 in I0s);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "I0s_failed = I0s_liks.==-Inf\nI0s_success = I0s[.!I0s_failed]\nI0s_liks_success = I0s_liks[.!I0s_failed]\nÎ₀ = I0s_success[argmax(I0s_liks_success)]"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(I0s,\n    I0s_liks,\n    xlabel=\"I₀\",\n    ylabel=\"Log likelihood\",\n    label=\"\",\n    legend=true,\n    marker=true,\n    xtick=I0s)\nvline!([u0[2]],label=\"True I₀\")\nvline!([Î₀],label=\"Estimated I₀\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion\n\nThis is a very naive implementation of a particle filter, but it illustrates the main features. Adding in measurement noise would actually improve performance in some ways, as simulations would no longer have to exactly match the observed data, and hence fewer particles would be needed."
      ],
      "metadata": {}
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.8.5"
    },
    "kernelspec": {
      "name": "julia-1.8",
      "display_name": "Julia 1.8.5",
      "language": "julia"
    }
  },
  "nbformat": 4
}
