{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Simulation and inference of a Markov model defined using PartiallyObservedMarkovProcesses.jl and Turing.jl\nSimon Frost (@sdwfrost), 2025-10-03\n\n## Introduction\n\n`pomp` is a popular R package that implements simulation and inference of **p**artially **o**bserved **M**arkov **p**rocesses, with a particular emphasis on epidemiological models. There is an early port of `pomp` to Julia, [`PartiallyObservedMarkovProcesses.jl`](https://github.com/kingaa/PartiallyObservedMarkovProcesses.jl) (referred to as `POMP.jl` below), that can simulate Markov processes as well as provide estimates of the log likelihood using a particle filter. This notebook demonstrates how to fit a simple discrete-time, stochastic SIR model to counts of daily new cases of a disease using particle Markov chain Monte Carlo, with a combination of `POMP.jl` and `Turing.jl`, and also investigates how underreporting can be modelled.\n\n## Libraries"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using PartiallyObservedMarkovProcesses\nusing Distributions\nusing DataFrames\nusing Loess\nusing Random\nusing Plots\nusing Base.Threads;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "Random.seed!(1234); # For reproducibility"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transitions\n\nTo simulate and infer parameters of a Markov process in `POMP.jl`, we need to define four components:\n\n- `rinit`: a draw from the initial states of the system;\n- `rprocess`: a draw from the random process;\n- `rmeasure`: a draw of the measured outcome, given the states; and\n- `logdmeasure`: the log density of the measured outcome, given the states.\n\nWe define a simple `rinit`, which returns a fixed initial state. Note that the parameters are passed as named states (following the semicolon in the function signature). We consider the number of susceptible (`S`), infected (`I`), recovered (`R`), and the cumulative number of infections (`C`)."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sir_rinit = function (;S₀,I₀,R₀,_...)\n    return (S=S₀, I=I₀, R=R₀, C=0)\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use a discrete time approximation to implement a Markov model for the states."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sir_rprocess = function(;t,S,I,R,C,β,γ,N,dt,_...)\n    infprob = 1-exp(-β*I/N*dt)\n    recprob = 1-exp(-γ*dt)\n    infection = rand(Binomial(S,infprob))\n    recovery = rand(Binomial(I,recprob))\n    return (S=S-infection,\n            I=I+infection-recovery,\n            R=R+recovery,\n            C=C+recovery,\n            )\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although in principle, we could include observed states in the above model, `POMP.jl` keeps the true states and the observed states separate. We can define a model in which we observe the true number of new cases per day, `C`, as follows."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sir_rmeasure_exact = function (;C,_...)\n    return (Y=C,)\nend\n\nsir_logdmeasure_exact = function (;Y,C,_...)\n    if Y==C\n        return 0.0\n    else\n        return -Inf\n    end\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "In practice, our observations are imperfect. One possible mechanism is underreporting, where fewer than the actual number of cases are observed. Here, we assume that a proportion, `q`, of new infections are observed, and use a binomial distribution to obtain the observations."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sir_rmeasure_underreport = function (;C,q,_...)\n    return (Y=rand(Binomial(C,q)),)\nend\n\nsir_logdmeasure_underreport = function (;Y,C,q,_...)\n    return logpdf(Binomial(C,q),Y)\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters and initial states\n\n`POMP.jl` takes parameters as named tuples; this is fast, and allows different types for different parameters. We include both the rate parameters as well as the initial states in this tuple."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "p = (β = 0.5, # Infectivity\n     γ = 0.25, # Recovery rate\n     q = 0.5, # Fraction of new cases observed\n     N  = 1000.0, # Total population size (as a float)\n     S₀ = 990, # Initial susceptibles\n     I₀ = 10, # Initial infected\n     R₀ = 0); # Initial recovered"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Times\n\n`POMP.jl` consider two timescales; one for the stochastic process (here in time steps of `δt=0.1`), and one for the observation process (`times`)."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "t₀ = 0.0\nδt = 0.1\ntimes = collect(0:1.0:40.0);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simulation\n\nWe first generated simulated data (states and observations). The `simulate` function takes paramters, the initial time, the observation time, as well as our `rinit`, `rprocess`, `rmeasure`, and `logdmeasure` functions, and returns a `Matrix` of `PompObject`s; here, we just keep one. The `accumvars` argument resets variables to a given number (here, we reset `C` to zero) for each observed time step. In this way, `C` will represent the number of new infections per time step (summed over the smaller time steps `δt` taken by `rprocess`), rather than continuing to increase over the course of the simulation."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "s = simulate(\n        params = p,\n        t0 = t₀,\n        times = times,\n        accumvars = (C=0,),\n        rinit = sir_rinit,\n        rprocess = euler(sir_rprocess, dt = δt),\n        rmeasure = sir_rmeasure_underreport,\n        logdmeasure =  sir_logdmeasure_underreport\n    )[1];"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post-processing\n\nWe extract the simulation times and the states from the `PompObject`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "time_vec = s.times\nst = states(s);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The states from the `PompObject` are in the form of a vector of named tuples. We extract them using `getproperty`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "S_vec, I_vec, R_vec, C_vec = [getproperty.(st, s) for s in (:S, :I, :R, :C)];"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We extract the states and put into a `DataFrame`, which we will need for inference. Note that the `POMP.jl` helper function `obs` is used to extract the observations."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "Y_vec = getproperty.(obs(s), :Y)\ndat = DataFrame(time = time_vec, Y=Y_vec);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to provide information on the underreporting, we consider a case where at the final timepoint, we take a sample of individuals (`ZN`) from the population and make a random draw of how many recovered individuals there are in this sample (`Z`). This is intended to mimic the situation where we conduct a cross-sectional prevalence survey."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "ZN = 100\nZ = rand(Binomial(ZN,R_vec[end]/1000.0));"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting\n\nWe first plot the S, I, and R states."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(times,\n    [S_vec I_vec R_vec],\n    line = :path,\n    marker = (:circle, 3),\n    labels = [\"S\" \"I\" \"R\"])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a plot of the number of new cases, `C`, and the observed cases, `Y`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(times,\n    [C_vec Y_vec],\n    line = :path,\n    marker = (:circle, 3),\n    labels = [\"C\" \"Y\"])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obtaining the log likelihood using a particle filter\n\nWe create a new `PompObject` for inference purposes, following much the same format as `simulate`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "P = pomp(dat;\n         times=:time,\n         t0=t₀,\n         rinit=sir_rinit,\n         rprocess=euler(sir_rprocess, dt = δt),\n         rmeasure=sir_rmeasure_underreport,\n         logdmeasure=sir_logdmeasure_underreport,\n         params=p,\n         accumvars=(C=0,)\n);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can test the particle filter as follows, passing the `PompObject`, the number of particles, `Np`, and the parameters `p`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "Pf = pfilter(P, Np=1000, params=p)\nprintln(\n    \"PartiallyObservedMarkovProcesses.jl likelihood estimate: \",\n    round(Pf.logLik,digits=2)\n)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameter sweeps\n\nWe can use the particle filter to estimate the log likelihood for different values of parameters, in order to check that the particle filter is working as expected. Here, we consider sweeps over the infectivity, `β`, and the initial number of infected individuals, `I₀`, keeping all other parameters fixed at their true values."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "betas = collect(0.35:0.005:0.65)\nnbetas = length(betas)\nbeta_liks = Array{Float64}(undef,nbetas)\nThreads.@threads for i in 1:nbetas\n    pc = merge(p, (β=betas[i],))\n    beta_liks[i] = pfilter(P, Np=10000, params=pc).logLik\nend\n\nbetas_model = loess(betas, beta_liks)\nbeta_liks_smooth = Loess.predict(betas_model, betas)\nβ̂=betas[argmax(beta_liks_smooth)]\nplot(betas,\n    beta_liks_smooth,\n    xlabel=\"β\",\n    ylabel=\"Log likelihood\",\n    label=\"\",\n    legend=true,\n    marker=false)\nscatter!(betas, beta_liks, label=\"\")\nvline!([p.β],label=\"True β\")\nvline!([β̂],label=\"Estimated β\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "I0s = collect(5:1:50)\nnI0s = length(I0s)\nI0_liks = Array{Float64}(undef,nI0s)\nThreads.@threads for i in 1:nI0s\n    pc = merge(p, (I₀=I0s[i],))\n    I0_liks[i] = pfilter(P, Np=10000, params=pc).logLik\nend\n\nI0s_model = loess(I0s, I0_liks)\nI0_liks_smooth = Loess.predict(I0s_model, I0s)\nÎ₀=I0s[argmax(I0_liks_smooth)]\nplot(I0s,\n    I0_liks_smooth,\n    xlabel=\"I₀\",\n    ylabel=\"Log likelihood\",\n    label=\"\",\n    legend=true,\n    marker=false)\nscatter!(I0s, I0_liks, label=\"\")\nvline!([p.I₀],label=\"True I₀\")\nvline!([Î₀],label=\"Estimated I₀\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference using particle MCMC\n\nThe above parameter sweeps demonstrate that the particle filter is working, but are not suitable for robust inference. Here, we plug the estimate of the log likelihood from `POMP.jl` into a `Turing.jl` model, and sample from the posterior distribution using Metropolis-Hastings sampling. As there are random draws in `rprocess`, we cannot use automatic differentiation (although see [`StochasticAD.jl`](https://github.com/gaurav-arya/StochasticAD.jl).\n\n### Libraries for inference and visualization"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Turing\nusing MCMCChains\nusing StatsPlots;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fixed underreporting\n\nWe first consider estimating the infectivity, `β`, and the initial number of infected individuals, `I₀`, keeping all other parameters fixed at their true values, including the underreporting parameter, `q`. We define a Turing model, passing the `PompObject` returned from `pomp`, which contains the data and the parameters. This is a thing wrapper around `POMP.pfilter`, where we just have to define priors on the parameters we wish to estimate, and add the log likelihood returned from the particle filter using `Turing.@addlogprob!`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@model function sir_particle_mcmc_fixed_q(P)\n    # Priors for the parameters we want to estimate\n    β ~ Uniform(0.25, 0.75)\n    I₀ ~ DiscreteUniform(5, 50)\n    \n    # Create parameter tuple with current MCMC values\n    current_params = merge(P.params, (β=β, I₀=I₀))\n\n    # Compute particle filter likelihood\n    pf_result = pfilter(P, Np=1000, params=current_params)  # Reduced particles for speed\n    \n    # Add the log-likelihood to the model\n    Turing.@addlogprob! pf_result.logLik\n    \n    return nothing\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We instantiate the model."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sir_model_fixed_q = sir_particle_mcmc_fixed_q(P);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We sample from the model using the `MH` (Metropolis-Hastings) sampler from `Turing.jl`. This sampler does not need gradients (and hence can be applied to our stochastic model) and works with discrete parameters (such as `I₀`), while `Turing.jl` takes care of managing mapping the constrained parameters in our model to unconstrained parameters in the sampler."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "n_samples = 11000\nn_chains = 2\nchain_fixed_q = sample(sir_model_fixed_q,\n                          MH(),\n                          MCMCThreads(),\n                          n_samples,\n                          n_chains;\n                          progress=false);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "describe(chain_fixed_q)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(chain_fixed_q)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Misspecification of underreporting\n\nIt is common in analyses of case data to assume that all cases have been observed; here, we set `q=1` to look at the effect of this assumption, given that only 50% of cases were observed in our simulated data."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@model function sir_particle_mcmc_incorrect_q(P)\n    # Priors for the parameters we want to estimate\n    β ~ Uniform(0.25, 0.75)\n    I₀ ~ DiscreteUniform(5, 50)\n    \n    # Create parameter tuple with current MCMC values\n    current_params = merge(P.params, (β=β, I₀=I₀, q=1.0))\n\n    # Compute particle filter likelihood\n    pf_result = pfilter(P, Np=1000, params=current_params)  # Reduced particles for speed\n    \n    # Add the log-likelihood to the model\n    Turing.@addlogprob! pf_result.logLik\n    \n    return nothing\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sir_model_incorrect_q = sir_particle_mcmc_incorrect_q(P);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "n_samples = 11000\nn_chains = 2\nchain_incorrect_q = sample(sir_model_incorrect_q,\n                           MH(),\n                           MCMCThreads(),\n                           n_samples,\n                           n_chains;\n                           progress=false);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "describe(chain_incorrect_q)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(chain_incorrect_q)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the estimate of the initial number of infected has not changed much, the estimate of the infectivity, `β`, is much lower i.e. we would think that the basic reproductive number is much less than the actual value if we mistakenly assumed that we had sampled all cases.\n\n## Estimation of underreporting\n\nWe can use additional information in order to estimate and correct for underreporting. Here, we assume that we have information on how many individuals have recovered at the end of the observation period. We assume that `ZN` individuals are sampled, and `Z_obs` are recovered; in practice, such information could come from a prevalence survey. This example shows how we can combine information from the `POMP.jl` model with external information specified within the `Turing.jl` model."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@model function sir_particle_mcmc_estimate_q(P, Z_obs, ZN)\n    # Priors for the parameters we want to estimate\n    β ~ Uniform(0.25, 0.75)\n    I₀ ~ DiscreteUniform(5, 50)\n    q ~ Uniform(0.25, 0.75)\n    \n    # Create parameter tuple with current MCMC values\n    current_params = merge(P.params, (β=β, I₀=I₀, q=q))\n\n    # Compute particle filter likelihood\n    pf_result = pfilter(P, Np=1000, params=current_params)  # Reduced particles for speed\n\n    # Calculate contribution from end prevalence study\n    zp = pf_result.traj[end][:R]/1000.0\n    zp = max(min(zp,1.0),0.0) # To ensure boundedness\n    Z_obs ~ Binomial(ZN, zp)\n\n    # Add the log-likelihood to the model\n    Turing.@addlogprob! pf_result.logLik\n    \n    return nothing\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sir_model_estimate_q = sir_particle_mcmc_estimate_q(P, Z, ZN);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "n_samples = 11000\nn_chains = 2\nchain_estimate_q = sample(sir_model_estimate_q,\n                          MH(),\n                          MCMCThreads(),\n                          n_samples,\n                          n_chains;\n                          progress=false);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "describe(chain_estimate_q)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(chain_estimate_q)"
      ],
      "metadata": {},
      "execution_count": null
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.12.0"
    },
    "kernelspec": {
      "name": "julia-1.12",
      "display_name": "Julia 1.12.0",
      "language": "julia"
    }
  },
  "nbformat": 4
}
