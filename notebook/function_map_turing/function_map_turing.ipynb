{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Inference of a function map using Turing.jl\nSimon Frost (@sdwfrost), 2025-10-04\n\n## Introduction\n\nIn this notebook we demonstrate how to implement a discrete time function map model in Julia, and perform Bayesian inference using Turing.jl. The model is a simple SIR model with an additional state variable to track cumulative incidence. We assume that the number of observed cases in each time step is a binomial sample of the true incidence, with a reporting probability `q`. The structure of this notebook is similar to that of the [Markov POMP tutorial](https://github.com/epirecipes/sir-julia/markdown/markov_pomp/markov_pomp.md), except by choosing a function map rather than a Markov model, we can use automatic differentiation and the NUTS sampler in Turing.jl, as (a) there is no random number generation during inference and (b) all the parameters are continuous.\n\n## Libraries"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Turing\nusing MCMCChains\nusing Distributions\nusing Random\nusing Plots\nusing StatsPlots\nusing Base.Threads;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The binomial distribution in `Distributions.jl` only accepts integer values, so we use a custom `GeneralizedBinomial` distribution that can handle non-integer values. We include the `GeneralizedBinomial` distribution from a separate file."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "include(\"generalized_binomial.jl\")\nimport .GeneralizedBinomialExt: GeneralizedBinomial;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility functions\n\nTo assist in comparison with the continuous time models, we define a function that takes a constant rate, `r`, over a timespan, `t`, and converts it to a proportion."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@inline function rate_to_proportion(r,t)\n    1-exp(-r*t)\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transitions\n\nWe define a function that takes the 'old' state variables, `u`, and writes the 'new' state variables into `du.` Note that the timestep, `δt`, is passed as an explicit parameter."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function sir_map!(du,u,p,t)\n    (S, I, R, C) = u\n    (β, γ, q, N, δt) = p\n    infection = rate_to_proportion(β*I/N, δt)*S\n    recovery = rate_to_proportion(γ, δt)*I\n    @inbounds begin\n        du[1] = S - infection\n        du[2] = I + infection - recovery\n        du[3] = R + recovery\n        du[4] = C + infection\n    end\n    nothing\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function solve_map(f, u0, nsteps, p)\n    # Pre-allocate array with correct type\n    sol = similar(u0, length(u0), nsteps + 1)\n    # Initialize the first column with the initial state\n    sol[:, 1] = u0\n    # Iterate over the time steps\n    @inbounds for t in 2:nsteps+1\n        u = @view sol[:, t-1] # Get the current state\n        du = @view sol[:, t]  # Prepare the next state\n        f(du, u, p, t)        # Call the function to update du\n    end\n    return sol\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time domain"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "δt = 1.0 # Time step\nnsteps = 40\ntmax = nsteps*δt\nt = 0.0:δt:tmax;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial conditions\n\nNote that we define the state variables as floating point rather than as integers (c.f. the Markov model examples), as we will be treating the initial number of infected individuals as a continuous parameter in our inference."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "u0 = [990.0, 10.0, 0.0, 0.0];"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameter values\n\nWe define the parameters as a named tuple; this will make it easier to modify individual parameters during inference."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "p = (β=0.5, γ=0.25, q=0.75, N=1000.0, δt=δt);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the model"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sol_map = solve_map(sir_map!, u0, nsteps, p);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post-processing\n\nWe unpack the solution into separate variables for convenience."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "S, I, R, C = eachrow(sol_map);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting\n\nWe can now plot the results."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(t,\n     [S I R C],\n     label=[\"S\" \"I\" \"R\" \"C\"],\n     xlabel=\"Time\",\n     ylabel=\"Number\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference using Turing.jl\n\nWe first simulate some observed data, `Y`, by taking a binomial sample of the incidence (the difference in cumulative cases between time steps) using a parameter `q`, which represents the fraction of cases that are reported. We use `GeneralizedBinomial` to allow for non-integer values of `C`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "Y = rand.(GeneralizedBinomial.(C[2:end]-C[1:end-1], p.q));"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to provide additional information on the reporting probability, we will also draw a sample of individuals from the final timepoint, and record how many of them have been infected and recovered. We will use this information to estimate the reporting level, `q`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "ZN = 100\nZ = rand(GeneralizedBinomial(ZN, R[end]/p.N));"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now define a function to calculate the log probability density of the observed case data, `Y`, given the output from `solve_map`. This function runs the model using the current parameter values, extracts the predicted incidence per time step, and calculates the log probability density using the `GeneralizedBinomial` distribution."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function logpdf(Y, sol, q)\n    C = sol[4,:]\n    ll = 0.0\n    X = (C[2:end] .- C[1:end-1])\n    for i in 1:length(Y)\n        ll += Distributions.logpdf(GeneralizedBinomial(X[i], q), Y[i])\n    end\n    return ll\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Estimation using case data only\n\nThe Turing model takes the observed data, `Y`, the initial conditions, `u0`, the number of time steps, `nsteps`, and the fixed parameters, `p`, as arguments. It defines priors for the parameters we want to estimate (`β` and `I₀`), updates the initial conditions and parameter tuple with the current MCMC values, and adds the log-likelihood to the model using `Turing.@addlogprob!`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@model function sir_map_estimate_q(Y, u0, nsteps, p)\n    # Priors for the parameters we want to estimate\n    β ~ Uniform(0.25, 0.75)\n    I₀ ~ Uniform(5.0, 50.0)\n    q ~ Uniform(0.1, 0.9)\n\n    # Create parameter tuple with current MCMC values\n    p_new = merge(p, (β = β, q = q))\n    u0_new = [p.N - I₀, I₀, 0.0, 0.0]\n\n    # Solve the model with the current parameters\n    sol = solve_map(sir_map!, u0_new, nsteps, p_new)\n\n    # Add the log-likelihood of the cases to the model\n    Turing.@addlogprob! logpdf(Y, sol, q)\n\n    return nothing\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sir_model_estimate_q = sir_map_estimate_q(Y, u0, nsteps, p)\nchain_estimate_q = sample(sir_model_estimate_q, NUTS(0.65), 10000; progress=false);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "describe(chain_estimate_q)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(chain_estimate_q)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "nsims = 1000\nI₀_means = Array{Float64}(undef, nsims)\nβ_means = Array{Float64}(undef, nsims)\nq_means = Array{Float64}(undef, nsims)\nI₀_coverage = Array{Float64}(undef, nsims)\nβ_coverage = Array{Float64}(undef, nsims)\nq_coverage = Array{Float64}(undef, nsims)\nThreads.@threads for i in 1:nsims\n    Y_sim = rand.(GeneralizedBinomial.(C[2:end]-C[1:end-1], p.q))\n    r = sample(sir_map_estimate_q(Y_sim, u0, nsteps, p),\n               NUTS(1000,0.65),\n               10000;\n               verbose=false,\n               progress=false,\n               initial_params=(β=0.5, I₀=10.0, q=0.75))\n    I₀_means[i] = mean(r[:I₀])\n    I₀_cov = sum(r[:I₀] .<= u0[2]) / length(r[:I₀])\n    β_means[i] = mean(r[:β])\n    β_cov = sum(r[:β] .<= p.β) / length(r[:β])\n    q_means[i] = mean(r[:q])\n    q_cov = sum(r[:q] .<= p.q) / length(r[:β])\n    I₀_coverage[i] = I₀_cov\n    β_coverage[i] = β_cov\n    q_coverage[i] = q_cov\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# Convenience function to check if the true value is within the credible interval\nfunction in_credible_interval(x, lwr=0.025, upr=0.975)\n    return x >= lwr && x <= upr\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "pl_β_coverage = histogram(β_coverage, bins=0:0.1:1.0, label=false, title=\"β\", ylabel=\"Density\", density=true, xrotation=45, xlim=(0.0,1.0))\npl_I₀_coverage = histogram(I₀_coverage, bins=0:0.1:1.0, label=false, title=\"i₀\", ylabel=\"Density\", density=true, xrotation=45, xlim=(0.0,1.0))\npl_q_coverage = histogram(q_coverage, bins=0:0.1:1.0, label=false, title=\"q\", ylabel=\"Density\", density=true, xrotation=45, xlim=(0.0,1.0))\nplot(pl_β_coverage, pl_I₀_coverage, pl_q_coverage, layout=(1,3), plot_title=\"Distribution of CDF of true value\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The coverage of the 95% credible intervals is given by the proportion of simulations where the true value is within the interval."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sum(in_credible_interval.(β_coverage)) / nsims"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sum(in_credible_interval.(I₀_coverage)) / nsims"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sum(in_credible_interval.(q_coverage)) / nsims"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also look at the distribution of the posterior means, which should fall around the true value."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "pl_β_means = histogram(β_means, label=false, title=\"β\", ylabel=\"Density\", density=true, xrotation=45, xlim=(0.48, 0.52))\nvline!([p.β], label=\"True value\")\npl_I₀_means = histogram(I₀_means, label=false, title=\"I₀\", ylabel=\"Density\", density=true, xrotation=45, xlim=(5.0,15.0))\nvline!([u0[2]], label=\"True value\")\npl_q_means = histogram(q_means, label=false, title=\"q\", ylabel=\"Density\", density=true, xrotation=45, xlim=(0.65,0.85))\nvline!([p.q], label=\"True value\")\nplot(pl_β_means, pl_I₀_means, pl_q_means, layout=(1,3), plot_title=\"Distribution of posterior means\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estimation using case data and final prevalence survey"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@model function sir_map_estimate_q_prevalence(Y, Z, ZN, u0, nsteps, p)\n    # Priors for the parameters we want to estimate\n    β ~ Uniform(0.25, 0.75)\n    I₀ ~ Uniform(5.0, 50.0)\n    q ~ Uniform(0.1, 0.9)\n\n    # Create parameter tuple with current MCMC values\n    p_new = merge(p, (β = β, q = q))\n    u0_new = [p.N - I₀, I₀, 0.0, 0.0]\n\n    # Solve the model with the current parameters\n    sol = solve_map(sir_map!, u0_new, nsteps, p_new)\n\n    # Add the log-likelihood of the cases to the model\n    Turing.@addlogprob! logpdf(Y, sol, q)\n    \n    # Calculate contribution from end prevalence study\n    zp = sol[3,end]/p.N\n    zp = max(min(zp,1.0),0.0) # To ensure boundedness\n    Z ~ GeneralizedBinomial(ZN, zp)\n\n    return nothing\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sir_model_estimate_q_prevalence = sir_map_estimate_q_prevalence(Y, Z, ZN, u0, nsteps, p)\nchain_estimate_q_prevalence = sample(sir_model_estimate_q_prevalence, NUTS(0.65), 10000; progress=false);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "describe(chain_estimate_q_prevalence)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(chain_estimate_q_prevalence)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "I₀_prev_means = Array{Float64}(undef, nsims)\nβ_prev_means = Array{Float64}(undef, nsims)\nq_prev_means = Array{Float64}(undef, nsims)\nI₀_prev_coverage = Array{Float64}(undef, nsims)\nβ_prev_coverage = Array{Float64}(undef, nsims)\nq_prev_coverage = Array{Float64}(undef, nsims)\nThreads.@threads for i in 1:nsims\n    Y_sim = rand.(GeneralizedBinomial.(C[2:end]-C[1:end-1], p.q))\n    Z_sim = rand(GeneralizedBinomial(ZN, R[end]/p.N))\n    r = sample(sir_map_estimate_q_prevalence(Y_sim, Z_sim, ZN, u0, nsteps, p),\n               NUTS(1000,0.65),\n               10000;\n               verbose=false,\n               progress=false,\n               initial_params=(β=0.5, I₀=10.0, q=0.75))\n    I₀_prev_means[i] = mean(r[:I₀])\n    I₀_cov = sum(r[:I₀] .<= u0[2]) / length(r[:I₀])\n    β_prev_means[i] = mean(r[:β])\n    β_cov = sum(r[:β] .<= p.β) / length(r[:β])\n    q_prev_means[i] = mean(r[:q])\n    q_cov = sum(r[:q] .<= p.q) / length(r[:q])\n    I₀_prev_coverage[i] = I₀_cov\n    β_prev_coverage[i] = β_cov\n    q_prev_coverage[i] = q_cov\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "pl_β_prev_coverage = histogram(β_prev_coverage, bins=0:0.1:1.0, label=false, title=\"β\", ylabel=\"Density\", density=true, xrotation=45, xlim=(0.0,1.0))\npl_I₀_prev_coverage = histogram(I₀_prev_coverage, bins=0:0.1:1.0, label=false, title=\"i₀\", ylabel=\"Density\", density=true, xrotation=45, xlim=(0.0,1.0))\npl_q_prev_coverage = histogram(q_prev_coverage, bins=0:0.1:1.0, label=false, title=\"q\", ylabel=\"Density\", density=true, xrotation=45, xlim=(0.0,1.0))\nplot(pl_β_prev_coverage, pl_I₀_prev_coverage, pl_q_prev_coverage, layout=(1,3), plot_title=\"Distribution of CDF of true value\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The coverage of the 95% credible intervals is given by the proportion of simulations where the true value is within the interval."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sum(in_credible_interval.(β_prev_coverage)) / nsims"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sum(in_credible_interval.(I₀_prev_coverage)) / nsims"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sum(in_credible_interval.(q_prev_coverage)) / nsims"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also look at the distribution of the posterior means, which should fall around the true value."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "pl_β_prev_means = histogram(β_prev_means, label=false, title=\"β\", ylabel=\"Density\", density=true, xrotation=45, xlim=(0.48, 0.52))\nvline!([p.β], label=\"True value\")\npl_I₀_prev_means = histogram(I₀_prev_means, label=false, title=\"I₀\", ylabel=\"Density\", density=true, xrotation=45, xlim=(5.0,15.0))\nvline!([u0[2]], label=\"True value\")\npl_q_prev_means = histogram(q_prev_means, label=false, title=\"q\", ylabel=\"Density\", density=true, xrotation=45, xlim=(0.65,0.85))\nvline!([p.q], label=\"True value\")\nplot(pl_β_prev_means, pl_I₀_prev_means, pl_q_prev_means, layout=(1,3), plot_title=\"Distribution of posterior means\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion\n\nThe use of a continuous state, deterministic model with continuous parameters allowed us to use the NUTS sampler in Turing.jl, which is generally more efficient than standard Metropolis Hastings. The additional data on underreporting provided to the model in this example did not appear to add very much information to the inference."
      ],
      "metadata": {}
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.12.0"
    },
    "kernelspec": {
      "name": "julia-1.12",
      "display_name": "Julia 1.12.0",
      "language": "julia"
    }
  },
  "nbformat": 4
}
