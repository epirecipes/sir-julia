using POMDPs, POMDPTools, QuickPOMDPs
using MCTS
using Distributions
using Plots

@inline function rate_to_proportion(r::Float64,t::Float64)
    1-exp(-r*t)
end;

# u0 is initial conditions, s0 includes the
# cumulative intervention force (Ï…_cumulative)
u0 = (990,10,0);
s0 = (u0...,0.0)

Î´t = 0.1
Î² = 0.5 # infectivity rate
Î³ = 0.25 # recovery rate
Ï…_max = 0.5 # maximum intervention
Ï…_total = 10.0; # maximum cost

ð’œ = collect(0:0.05:Ï…_max)

sir_mdp = QuickMDP(
    actiontype = Float64,
    actions = function(s)
        if s[end] >= Ï…_total
            return [0.0]
        else
            return ð’œ
        end
    end,
    reward = function(s, a, sp)
        return -sp[3]
    end,
    transition = function(s, a)
        ImplicitDistribution() do rng
            (S,I,C) = s[1:3]
            Ï…_cumulative = s[end]
            N = sum(u0)
            ifrac = rate_to_proportion((1-a)*Î²*I/N,Î´t)
            rfrac = rate_to_proportion(Î³,Î´t)
            infection=rand(rng,Binomial(S,ifrac))
            recovery=rand(rng,Binomial(I,rfrac))
            return (S-infection,I+infection-recovery,C+infection,Ï…_cumulative+(a*Î´t))
        end
    end,
    initialstate = Deterministic(s0),
    isterminal = s -> s[2] == 0,
    discount = 0.95
)

# solver = MCTSSolver(n_iterations=500,depth=100)
solver = DPWSolver(n_iterations=500,depth=20,show_progress=true)
planner = solve(solver, sir_mdp)

# action0, info0 = action_info(planner, s0)

hr = HistoryRecorder(max_steps=10000)
h = simulate(hr, sir_mdp, planner)

state_trajectory = transpose(hcat([collect(h[i][:s][1:3]) for i in eachindex(h)]â€¦))
action_trajectory = [h[i][:a] for i in eachindex(h)]

plot(state_trajectory)
plot(action_trajectory)
